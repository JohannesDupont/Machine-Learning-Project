{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c493538-1610-4212-b6dd-b735f3ecde29",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.distributed as dist\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torch.utils.data.distributed\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import transforms\n",
    "from PIL import Image, ImageDraw\n",
    "#os.chdir('code')\n",
    "\n",
    "from utils.utils import CustomDataset\n",
    "from models.model_SE import *\n",
    "from models.model_ECA import *\n",
    "from utils.helper import *\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9f4125e-4ff5-4e4b-b031-82a4cabc720f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6fe61b1-4201-4532-be61-0fcc2dfc5aa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../data/train.json') as json_data:\n",
    "    train_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e3f9186c-1590-4ef3-874f-471b42bcaa9d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('../data/test.json') as json_data:\n",
    "    test_data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b17aec7-ada8-4be8-9a1e-4d443a7920d5",
   "metadata": {},
   "source": [
    "### Get Train Loader and Test Loader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3966c8e-8127-48ea-ac05-e9dbd11fc5ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "# train data\n",
    "custom_train_dataset = CustomDataset(train_data, '../data/train', transform=transform)\n",
    "train_data_loader = torch.utils.data.DataLoader(custom_train_dataset, batch_size=4, shuffle=True, num_workers=0)\n",
    "\n",
    "# test data\n",
    "custom_test_dataset = CustomDataset(test_data, '../data/test', transform=None)\n",
    "test_data_loader = torch.utils.data.DataLoader(custom_test_dataset, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df431924-0355-436d-9703-383abe0d005e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26a831ae-0c98-4b0d-9247-e6678fc00590",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "best_prec1 = 0\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    dice_loss = AverageMeter()\n",
    "    losses_batch = {}\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, data in enumerate(train_loader):\n",
    "        \n",
    "        target = data['annotations']\n",
    "        input_image = data['image']\n",
    "        \n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        if args.gpu is not None:\n",
    "            input = input.cuda(args.gpu, non_blocking=True)\n",
    "        target = target.cuda(args.gpu, non_blocking=True)\n",
    "        \n",
    "        output = model(input_image)\n",
    "        \n",
    "        output_probs = torch.sigmoid(output)\n",
    "        \n",
    "        output = output.squeeze(1)  \n",
    "        output_binary = (output_probs > 0.5).float()\n",
    "\n",
    "        target = (target > 0).float()\n",
    "        target = target.squeeze(1)  \n",
    "        \n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        dice = dice_coeff(output_binary, target).item()\n",
    "        #print('---'*10,'dice', dice,'---'*10)\n",
    "        \n",
    "        losses.update(loss.item(), input_image.size(0))\n",
    "        dice_loss.update(dice, input_image.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % args.print_freq == 0:\n",
    "            print(f\"Epoch {epoch}, Loss {loss}, avg. Dice {dice_loss.avg} curr. Dice {dice}\")\n",
    "            print('---'*50)\n",
    "\n",
    "          \n",
    "    return losses.avg, dice_loss.avg\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    directory = \"runs/%s/\"%(args.arch + '_' + args.action)\n",
    "    \n",
    "    filename = directory + filename\n",
    "    torch.save(state, filename)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filename, directory + 'model_best.pth.tar')\n",
    "\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"Sets the learning rate to the initial LR decayed by 10 every 30 epochs\"\"\"\n",
    "    lr = args.lr * (0.1 ** (epoch // 30))\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = lr\n",
    "\n",
    "\n",
    "def dice_coeff(pred, target):\n",
    "    \"\"\"\n",
    "    Calculate the Dice coefficient for batch of predictions and targets.\n",
    "\n",
    "    Args:\n",
    "        pred: Predicted tensor of shape (N, C, H, W), where N is the batch size.\n",
    "        target: Ground truth tensor of shape (N, C, H, W), with the same dimensions as pred.\n",
    "\n",
    "    Returns:\n",
    "        dice_score: Computed Dice coefficient.\n",
    "    \"\"\"\n",
    "    smooth = 1.0  # Add smooth to avoid divide by zero error\n",
    "    \n",
    "    # Flatten the tensors to make the computation easier\n",
    "    pred_flat = pred.contiguous().view(pred.size(0), -1)\n",
    "    target_flat = target.contiguous().view(target.size(0), -1)\n",
    "    \n",
    "    intersection = (pred_flat * target_flat).sum(1)  # Sum over the spatial dimensions\n",
    "    \n",
    "    #print('pred_flat', pred_flat.sum(1))\n",
    "    #print('target_flat', target_flat.sum(1))\n",
    "    \n",
    "    dice_score = (2. * intersection + smooth) / (pred_flat.sum(1) + target_flat.sum(1) + smooth)\n",
    "    \n",
    "    # We take the mean over the batch\n",
    "    dice_score = dice_score.mean()\n",
    "    \n",
    "    return dice_score\n",
    "\n",
    "\n",
    "def data_save(root, file):\n",
    "    if not os.path.exists(root):\n",
    "        os.mknod(root)\n",
    "    file_temp = open(root, 'r')\n",
    "    lines = file_temp.readlines()\n",
    "    if not lines:\n",
    "        epoch = -1\n",
    "    else:\n",
    "        epoch = lines[-1][:lines[-1].index(' ')]\n",
    "    epoch = int(epoch)\n",
    "    file_temp.close()\n",
    "    file_temp = open(root, 'a')\n",
    "    for line in file:\n",
    "        if line > epoch:\n",
    "            file_temp.write(str(line) + \" \" + str(file[line]) + '\\n')\n",
    "    file_temp.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7e8d39-f6ff-4ff6-ac6b-1c23cd166838",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Model "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6fa250-eb05-4af2-92ee-f1947ee39c49",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Arguments for model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13f2e9bd-9cfa-40a7-bca1-6e031a98fecd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class args():\n",
    "    gpu = None\n",
    "    distributed = False\n",
    "    seed = 42\n",
    "    pretrained = False\n",
    "    arch = 'eca_resnet50'\n",
    "    ksize=None\n",
    "    lr = 0.01\n",
    "    momentum = 0.9\n",
    "    weight_decay = 1e-4\n",
    "    evaluate = False\n",
    "    action = ''\n",
    "    epochs = 100\n",
    "    start_epoch = 0\n",
    "    print_freq = 100\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d43500-daed-4e3c-9f68-2dc5f0bca92d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "global args, best_dice\n",
    "\n",
    "if args.seed is not None:\n",
    "    random.seed(args.seed)\n",
    "    torch.manual_seed(args.seed)\n",
    "    cudnn.deterministic = True\n",
    "    warnings.warn('You have chosen to seed training. '\n",
    "                  'This will turn on the CUDNN deterministic setting, '\n",
    "                  'which can slow down your training considerably! '\n",
    "                  'You may see unexpected behavior when restarting '\n",
    "                  'from checkpoints.')\n",
    "\n",
    "if args.gpu is not None:\n",
    "    warnings.warn('You have chosen a specific GPU. This will completely '\n",
    "                  'disable data parallelism.')\n",
    "\n",
    "\n",
    "#if args.distributed:\n",
    "#    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n",
    "#                            world_size=args.world_size)\n",
    "\n",
    "# create model\n",
    "\n",
    "else:\n",
    "    print(\"=> creating model '{}'\".format(args.arch))\n",
    "    if args.ksize == None:\n",
    "        model = eca_resnet50()\n",
    "    else:\n",
    "        model = eca_resnet50(k_size=args.ksize)\n",
    "\n",
    "if args.gpu is not None:\n",
    "    model = model.cuda(args.gpu)\n",
    "    \n",
    "elif args.distributed:\n",
    "    model.cuda()\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[0, 1])\n",
    "\n",
    "else:\n",
    "    if args.arch.startswith('alexnet') or args.arch.startswith('vgg'):\n",
    "        model.features = torch.nn.DataParallel(model.features)\n",
    "        model.cuda()\n",
    "    else:\n",
    "        model = torch.nn.DataParallel(model).cuda()\n",
    "\n",
    "print(model)\n",
    "\n",
    "# get the number of models parameters\n",
    "print('Number of models parameters: {}'.format(sum([p.data.nelement() for p in model.parameters()])))\n",
    "\n",
    "# define loss function (criterion) and optimizer\n",
    "#criterion = nn.CrossEntropyLoss().cuda(args.gpu)\n",
    "criterion = torch.nn.BCEWithLogitsLoss().cuda(args.gpu)\n",
    "\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), args.lr,\n",
    "                            momentum=args.momentum,\n",
    "                            weight_decay=args.weight_decay)\n",
    "\n",
    "'''# optionally resume from a checkpoint\n",
    "if args.resume:\n",
    "    if os.path.isfile(args.resume):\n",
    "        print(\"=> loading checkpoint '{}'\".format(args.resume))\n",
    "        checkpoint = torch.load(args.resume)\n",
    "        args.start_epoch = checkpoint['epoch']\n",
    "        best_prec1 = checkpoint['best_prec1']\n",
    "        model.load_state_dict(checkpoint['state_dict'])\n",
    "        optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "        print(\"=> loaded checkpoint '{}' (epoch {})\"\n",
    "              .format(args.resume, checkpoint['epoch']))\n",
    "        del checkpoint\n",
    "    else:\n",
    "        print(\"=> no checkpoint found at '{}'\".format(args.resume))'''\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "if args.distributed:\n",
    "    train_sampler = torch.utils.data.distributed.DistributedSampler(train_dataset)\n",
    "else:\n",
    "    train_sampler = None\n",
    "\n",
    "train_loader = train_data_loader\n",
    "\n",
    "if args.evaluate:\n",
    "    m = time.time()\n",
    "    _, _ =validate(val_loader, model, criterion)\n",
    "    n = time.time()\n",
    "    print((n-m)/3600)\n",
    "    \n",
    "\n",
    "directory = \"runs/%s/\"%(args.arch + '_' + args.action)\n",
    "if not os.path.exists(directory):\n",
    "    os.makedirs(directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "add72d00-d1b4-46a3-a561-8f4bcb9e7bc4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss 6.8329877853393555, avg. Dice 0.1882462501525879 curr. Dice 0.1882462501525879\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.009895511004659865\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 1, Loss 1.1494940519332886, avg. Dice 0.29086318612098694 curr. Dice 0.29086318612098694\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0035299293862448796\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 2, Loss 1.8592710494995117, avg. Dice 0.050585996359586716 curr. Dice 0.050585996359586716\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0025999337434768678\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 3, Loss 1.1379746198654175, avg. Dice 0.05392265319824219 curr. Dice 0.05392265319824219\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.002628389464484321\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 4, Loss 2.629199981689453, avg. Dice 0.059168945997953415 curr. Dice 0.059168945997953415\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0026366960340076023\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 5, Loss 1.4510529041290283, avg. Dice 0.2619916796684265 curr. Dice 0.2619916796684265\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.002594128449757894\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 6, Loss 1.1772050857543945, avg. Dice 0.10100997239351273 curr. Dice 0.10100997239351273\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0026112661759058633\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 7, Loss 1.0950618982315063, avg. Dice 0.009166020900011063 curr. Dice 0.009166020900011063\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.00261467178662618\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 8, Loss 0.7446675896644592, avg. Dice 0.18523040413856506 curr. Dice 0.18523040413856506\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0029344101084603203\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 9, Loss 0.6946035623550415, avg. Dice 0.3114403486251831 curr. Dice 0.3114403486251831\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.002578749921586778\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 10, Loss 0.6322967410087585, avg. Dice 0.15917803347110748 curr. Dice 0.15917803347110748\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.002607999973826938\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 11, Loss 0.28358712792396545, avg. Dice 0.5767381191253662 curr. Dice 0.5767381191253662\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0025864119662178885\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 12, Loss 0.710630476474762, avg. Dice 0.001981808338314295 curr. Dice 0.001981808338314295\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0025655884875191584\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 13, Loss 0.6402528285980225, avg. Dice 0.06238260492682457 curr. Dice 0.06238260492682457\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0026838362216949465\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 14, Loss 0.6504978537559509, avg. Dice 0.34535861015319824 curr. Dice 0.34535861015319824\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0025919532113605074\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 15, Loss 0.3815896809101105, avg. Dice 0.6119004487991333 curr. Dice 0.6119004487991333\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0026358358727561104\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 16, Loss 0.6745327115058899, avg. Dice 0.0026443488895893097 curr. Dice 0.0026443488895893097\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0025747983985477023\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 17, Loss 0.6941842436790466, avg. Dice 0.455791711807251 curr. Dice 0.455791711807251\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0025752700037426418\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 18, Loss 2.4696567058563232, avg. Dice 0.36087092757225037 curr. Dice 0.36087092757225037\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.002655488914913601\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 19, Loss 0.4405784606933594, avg. Dice 0.6390217542648315 curr. Dice 0.6390217542648315\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.0025866324371761748\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 20, Loss 0.38933005928993225, avg. Dice 0.1502867341041565 curr. Dice 0.1502867341041565\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "--------------------------------------------------------------------------------\n",
      "0.002580613758828905\n",
      "--------------------------------------------------------------------------------\n",
      "Epoch 21, Loss 0.9615553021430969, avg. Dice 0.5223449468612671 curr. Dice 0.5223449468612671\n",
      "------------------------------------------------------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m adjust_learning_rate(optimizer, epoch)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# train for one epoch\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# train(train_loader, model, criterion, optimizer, epoch)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m loss_temp, dice_ \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m Loss_plot[epoch] \u001b[38;5;241m=\u001b[39m loss_temp\n\u001b[1;32m     15\u001b[0m train_dice[epoch] \u001b[38;5;241m=\u001b[39m dice_\n",
      "Cell \u001b[0;32mIn[30], line 46\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(train_loader, model, criterion, optimizer, epoch)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# compute gradient and do SGD step\u001b[39;00m\n\u001b[1;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 46\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# measure elapsed time\u001b[39;00m\n",
      "File \u001b[0;32m/gpfs/milgram/project/shung/jd2823/conda_envs/rockall_score/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/gpfs/milgram/project/shung/jd2823/conda_envs/rockall_score/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "Loss_plot = {}\n",
    "train_dice = {}\n",
    "\n",
    "for epoch in range(args.start_epoch, args.epochs):\n",
    "    start_time = time.time()\n",
    "    if args.distributed:\n",
    "        train_sampler.set_epoch(epoch)\n",
    "    adjust_learning_rate(optimizer, epoch)\n",
    "\n",
    "    # train for one epoch\n",
    "    # train(train_loader, model, criterion, optimizer, epoch)\n",
    "    loss_temp, dice_ = train(train_loader, model, criterion, optimizer, epoch)\n",
    "    \n",
    "    Loss_plot[epoch] = loss_temp\n",
    "    train_dice[epoch] = dice_\n",
    "\n",
    "    data_save(directory + 'Loss_plot.txt', Loss_plot)\n",
    "    data_save(directory + 'train_dice.txt', train_dice)\n",
    "    \n",
    "\n",
    "    end_time = time.time()\n",
    "    time_value = (end_time - start_time) / 3600\n",
    "    print(\"-\" * 80)\n",
    "    print(time_value)\n",
    "    print(\"-\" * 80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981b551e-77c1-440d-90cf-76585c0fa1f9",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b518e74a-27c1-4a4c-9968-16e0f245a972",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#torch.save(model, 'trained_models/eca_resnet50_trained.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ededfc6e-fa05-4b5b-9a33-ff3e969f1348",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Constructing eca_resnet50......\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = eca_resnet50()\n",
    "\n",
    "# Load the whole object wrapped by DataParallel\n",
    "model_dp = torch.load('trained_models/eca_resnet50_trained.pth')\n",
    "\n",
    "# Unwrap the state dictionary\n",
    "state_dict = model_dp.module.state_dict()\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3424a8a0-76f1-48c6-af93-32f4189dc4c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dice_coefficient(y_true, y_pred):\n",
    "   \n",
    "    # Ensure boolean arrays, if not already:\n",
    "    y_true = np.asarray(y_true).astype(np.bool)\n",
    "    y_pred = np.asarray(y_pred).astype(np.bool)\n",
    "\n",
    "    # Calculate intersection and union:\n",
    "    intersection = np.logical_and(y_true, y_pred)\n",
    "    dice = 2. * intersection.sum() / (y_true.sum() + y_pred.sum())\n",
    "    \n",
    "    return dice\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c575f1b1-2a87-4ba4-8d90-37aaa86ad786",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_64253/3847900178.py:22: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  mask_np = mask.cpu().numpy().astype(np.float)  # Ensure mask is binary\n",
      "/tmp/ipykernel_64253/3735315904.py:4: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_true = np.asarray(y_true).astype(np.bool)\n",
      "/tmp/ipykernel_64253/3735315904.py:5: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  y_pred = np.asarray(y_pred).astype(np.bool)\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('predictions_ECA', exist_ok=True)\n",
    "device = torch.device(f\"cuda:{args.gpu}\" if args.gpu is not None else \"cpu\")\n",
    "\n",
    "\n",
    "for i_batch, sample_batched in enumerate(test_data_loader):\n",
    "    with torch.no_grad():  # No need to track gradients for visualization\n",
    "        image = sample_batched['image'][0]  # Assuming the image is the first item in the batch\n",
    "        mask = sample_batched['annotations'][0]\n",
    "\n",
    "        # Add batch dimension and send the tensor to the device\n",
    "        image_tensor = image.unsqueeze(0).to(device)\n",
    "\n",
    "        # Get prediction from the model\n",
    "        predicted_mask_tensor = model(image_tensor)\n",
    "\n",
    "        # Apply sigmoid to convert to probabilities\n",
    "        predicted_probs_tensor = torch.sigmoid(predicted_mask_tensor).squeeze(0)\n",
    "\n",
    "        # Threshold the probabilities to get a binary mask\n",
    "        predicted_mask_np = (predicted_probs_tensor > 0.5).cpu().numpy().astype(np.uint8)\n",
    "\n",
    "        mask_np = mask.cpu().numpy().astype(np.float)  # Ensure mask is binary\n",
    "        dice_score = dice_coefficient(mask_np.flatten(), predicted_mask_np.flatten())\n",
    "\n",
    "        # Squeeze the channel dimension if it's 1 to comply with Matplotlib requirements\n",
    "        mask_np_squeezed = np.squeeze(mask_np)\n",
    "        predicted_mask_np_squeezed = np.squeeze(predicted_mask_np)\n",
    "\n",
    "        # Plot original image, true mask, and predicted mask\n",
    "        plt.figure(figsize=(18, 6))\n",
    "\n",
    "        # Original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image.squeeze().numpy(), cmap='gray')  # Make sure to squeeze here as well if needed\n",
    "        plt.axis('off')\n",
    "        plt.title('Original Test Image')\n",
    "\n",
    "        # True mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(mask_np_squeezed, cmap='gray')  # Use the squeezed version of mask for display\n",
    "        plt.axis('off')\n",
    "        plt.title('True Mask')\n",
    "\n",
    "        # Predicted mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(predicted_mask_np_squeezed, cmap='gray')  # Use the squeezed version of predicted mask for display\n",
    "        plt.axis('off')\n",
    "        plt.title(f'Predicted Mask - Dice: {dice_score:.2f}')  # Include Dice score in the title\n",
    "\n",
    "        # Save the figure to the predictions folder\n",
    "        plt.savefig(f'predictions_ECA/batch_{i_batch}_image.png')\n",
    "        plt.close()  # Close the figure to free up memo\n",
    "\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855c8948-bc6a-404f-917d-60effa3f8d28",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
